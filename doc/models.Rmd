# Example Models


### Polynomial Trend Models

See [@PetrisPetroneEtAl2009, Sec 3.2; @WestHarrison1997, Ch 7]

A polynomial trend model of order $n$ has constant matrices $\mat{T}_t = \mat{T}$, $\mat{Z}_t = \mat{Z}$, and has a forecast function of the form,
$$
f_t(k) = \E(y_{t + k} | \vec{Y}_t) = a_{t,0} + a_{t,1} k + \cdots + a_{t, n - 1} k^{n -1}, \quad k \geq 0,
$$

#### Local Level Model

A special case of polynomial trend models is the *local level model* or *random walk plus noise*.
It is defined as,
$$
\begin{aligned}[t]
y_t &= \alpha_{t} + \varepsilon_t & \varepsilon_t &\sim N(0, \sigma^{\varepsilon}^2)\\
\alpha_{t + 1} &= \alpha_{t} + \eta_t & \eta_t &\sim N(0,
\sigma_{\eta}^2)
\end{aligned}
$$
This is a SSM with,
$$
\mat{T} = \mat{Z} = \mat{R} = \begin{bmatrix} 1 \end{bmatrix} ,
$$
and $Q = \sigma_{\eta}^2$ and $H = \sigma_{\varepsilon}^2$.

This model is equivalent to the intercept of a classical linear regression model,
$$
y_t = \mu + \varepsilon_t ,
$$
but in which the the intercept $\mu$ is allowed to vary with time.

See [@CommandeurKoopman2007, Ch 2; @WestHarrison1997] for more details.

##### Linear Growth Model

The state vector of a linear growth models is $\vec{\alpha}_t = (\mu_t, \beta_t)'$,
where $\mu_t$ is interpreted as the local level, and $\beta_t$ is interpreted as the local growth rate.

$$
\begin{aligned}[t]
y_t &= \mu_t + \varepsilon_t & \varepsilon_t &\sim N(0, H) \\
\mu_{t + 1} &= \mu_{t} + \beta_{t} + \eta_{\mu,t}  \\
\beta_{t + 1} &= \beta_{t} + \eta_{\beta,t} & \vec{\eta}_t = (\eta_{\mu,t}, \eta_{\beta,t})\T &\sim N(0, \mat{Q})
\end{aligned}
$$
which can be written as,
$$
\begin{aligned}[t]
y_t &=
\begin{bmatrix}
1 & 0
\end{bmatrix}
\vec{\alpha}_t
+ \varepsilon_t \\
\vec{\alpha}_{t + 1}
&=
\begin{bmatrix}
1 & 1 \\
0 & 1
\end{bmatrix}
\vec{\alpha}_t
+
\vec{\eta}_t & \vec{\eta}_t &\sim N(0, \mat{Q})
\end{aligned}
$$
This is a SSM with,
$$
\begin{aligned}[t]
\mat{Z} &=
\begin{bmatrix}
1 & 0
\end{bmatrix} \\
\mat{T} &=
\begin{bmatrix}
1 & 1 \\
0 & 1
\end{bmatrix} \\
\mat{R} &= \mat{I}_2
\end{aligned}
$$

#### nth-Order Polynomial Models

Then,
$$
\begin{aligned}[t]
y_t &= \mu_t + \varepsilon_t \\
\alpha_{1,t + 1} &= \alpha_{1,t} + \alpha_{2,t} + \cdots + \alpha_{n,t} + \eta_{1,t} \\
\alpha_{2,t + 1} &= \alpha_{2,t} + \cdots + \alpha_{n,t} + \eta_{2,t} \\
\vdots &= \vdots \\
\alpha_{n,t + 1} &= \alpha_{n,t} + \eta_{n,t} \\
\end{aligned}
$$
which can be written as,
$$
\begin{aligned}[t]
y_t &=
\begin{bmatrix}
1 & 0 & 0 & \cdots & 0
\end{bmatrix}
\vec{\alpha}_{t}
+ \varepsilon_t \\
\vec{\alpha}_{t + 1}
&=
\mat{U}_n
\vec{\alpha}_{t}
+
\mat{I}_n
\vec{\eta}_t
\end{aligned}
$$
where $\mat{U}_n$ is an $n \times n$ upper triangular matrix of unit elements,
$$
\mat{U}_n =
\begin{bmatrix}
1 & 1 & 1 & \cdots & 1 \\
0 & 0 & 1 & \cdots & 1 \\
0 & 0 & 1 & \cdots & 1 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1 \\
\end{bmatrix}
$$

This is a SSM with,
$$
\begin{aligned}[t]
\mat{Z} &=
\begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
\end{bmatrix} \\
\mat{T} &= \mat{U}_n \\
\mat{R} &= \mat{I}_n
\end{aligned}
$$

In general, $\mat{Q}$ can be unstructured. Since the scale of the derivatives are likely related,
it makes little sense to allow $\mat{Q}$ to be diagonal.
[@WestHarrison1997, Sec 7.1] suggest using the following structured form of $\mat{Q}$ in order to represent the correlations between states,
$$
\begin{aligned}[t]
\mat{R} &= \mat{U}_n \\
\mat{Q} &= \diag(q_1, q_2, \dots, q_n)
\end{aligned}
$$
Since $\mat{Q}$ is diagonal, the errors $\eta$ are uncorrelated, but $\mat{R} \mat{Q} \mat{R}\T$ allows for correlations between the states.


### Seasonal Factor Models


[@PetrisPetroneEtAl2009, Sec 3.2.2]

A seasonal factor model with $s$ seasons is,
$$
\begin{aligned}[t]
y_t &= \alpha_{1,t} + \varepsilon_t \\
\alpha_{1,t + 1} &= -\alpha_{1,t} -\alpha_{2,t} - \cdots -\alpha_{s,t} + \eta_{1,t} \\
\alpha_{2,t + 1} &= \alpha_{1,t} \\
\alpha_{3,t + 1} &= \alpha_{2,t} \\
\vdots &= \vdots \\
\alpha_{s,t + 1} &= \alpha_{s - 1,t}
\end{aligned}
$$
Note that all of the states evolve deterministically except for $\alpha_1$.
This can be written in SSM form as,
$$
\begin{aligned}[t]
y_t &=
\begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
\end{bmatrix}
\vec{\alpha}_t
+ \varepsilon_t &
\varepsilon_t & \sim N(0, H)  \\
\vec{\alpha}_{t + 1}
&=
\begin{bmatrix}
-1 & -1 & \dots & -1 & -1 \\
1 & 0 & \cdots & 0 & 0 \\
0 & 1 & \cdots & 0 & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \cdots & 1 & 0
\end{bmatrix}
\vec{\alpha}_{t}
+
\begin{bmatrix}
1 \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix}
\eta_t
&
\eta_t &\sim N(0, Q)
\end{aligned}
$$
This is a case of a SSM in which $r = 1 < m = s$.
Also, note that only the first state has a non-zero system disturbance.
This could be written with alternative forms of $\mat{R}$ and $\mat{Q}$, e.g.
$\mat{R} = \mat{I}_m$ and a diagonal $\mat{Q}$, but since none of the other
states are tied to the observation model, it is equivalent.

### Fourier Form Seasonal Models

[@PetrisPetroneEtAl2009, Ch 3.2.3-3.2.4; ]



### ARMA and ARIMA Models

In ARMA modeling, trend and season components are differenced and the resulting differenced series is modeled as a stationary time series.
Let $\Delta y_t = y_t - y_{t - 1}$, $\Delta^2 = \Delta(\Delta y_t)$, $\Delta_s y_t = y_t - y_{t - s}$,
$\Delta^2_s y_t = \Delta_s (\Delta_s y_t)$, and so on.
Difference into trend and season effects have been eliminated, giving the variable, $y^*_t = \Delta^d \Delta_s^D y_t$ for $d, D = 0, 1, \dots$, which is modeled as a an ARMA($p$, $q$) process,
$$
\begin{aligned}[t]
y^*_t &= \phi_1 y^*_{t - 1} + \cdots + \phi_p y^*_{t - p} + \zeta_t + \theta_1 \zeta_{t - 1} + \cdots + \theta_q \zeta_{t - q}, & \zeta_t &\sim N(0, \sigma_{\zeta}^2) \\
&= \sum_{j = 1}^{p} \phi_j y^*_{t - j} + \zeta_t + \sum_{j = 1}^{q} \theta_j \zeta_{t - j} \\
&= \sum_{j = 1}^{r} \phi_j y^*_{t - j} + \zeta_t + \sum_{j = 1}^{r - 1} \theta_j \zeta_{t - j} .
\end{aligned}
$$
In the third equation, $r = \max(p, q + 1)$, and $\phi_j = 0$ if $j > p$, and $\theta_j$ equation, some coefficients can be zero.

A state-space form of an ARMA model uses the following latent states,
$$
\vec{\alpha}_t =
\begin{pmatrix}
y_t \\
\phi_2 y_{t - 1} + \cdots + \phi_r y_{t - r + 1} + \theta_1 \zeta_t + \cdots + \theta_{r - 1} \zeta_{t - r + 1} \\
\phi_3 y_{t - 1} + \cdots + \phi_r y_{t - r + 2} + \theta_2 \zeta_t + \cdots + \theta_{r - 1} \zeta_{t - r + 3} \\
\vdots \\
\phi_r y_{t - 1} + \theta_{r - 1} \zeta_{t} \\
\end{pmatrix}
$$
The system matrices are,
$$
\begin{aligned}[t]
\mat{Z}_t = \mat{Z} = &=
\begin{bmatrix} 1 & 0 & 0 & \cdots & 0 \end{bmatrix} \\
\mat{H}_t = \mat{H} = &= 0 \\
\mat{T}_t = \mat{T} = &=
\begin{bmatrix}
\phi_1 & 1 &  & 0  \\
\vdots &   & \ddots &  \\
\phi_{r - 1} & 0 &  & 1 \\
\phi_{r} & 0 & \cdots & 0
\end{bmatrix} \\
\mat{R}_t = \mat{R} &=
\begin{bmatrix}
1 \\
\theta_1 \\
\vdots \\
\theta_{r - 1}
\end{bmatrix} \\
\eta &= \zeta_{t + 1}
\end{aligned}
$$

Instead of differencing prior to analysis, the differencing can be done within the state-space model.
For example, an ARIMA model with $p = 2$, $d = 2$, and $q = 1$ is
$$
\begin{aligned}[t]
y_t &= \begin{bmatrix} 1 & 1 & 1 & 0 \end{bmatrix} \vec{\alpha}_t \\
\alpha_{t + 1} &=
\begin{bmatrix}
1 & 1 & 1 & 0 \\
0 & 1 & 1 & 0 \\
0 & 0 & \phi_1 & 1 \\
0 & 0 & \phi_2 & 0
\end{bmatrix}
\vec{\alpha}_t +
\begin{bmatrix}
0 \\
0 \\
1 \\
\theta_1
\end{bmatrix}
\zeta_{t + 1} ,
\end{aligned}
$$
with
$$
\vec{\alpha}_t =
\begin{bmatrix}
y_{t - 1} \\
\Delta y_{t - 1} \\
y^*_t \\
\phi_2 y^*_{t - 1} + \theta_1 \zeta_t
\end{bmatrix}
$$
and $y^*_t = \Delta^2 y_t = \Delta (y_t - y_{t - 1})$.
The unknown non-stationary values of $y_0$ and $\Delta y_0$ in the initial state vector $\vec{\alpha}_1$
need to be initialized.
This approach can easily extend to different levels of differencing and seasonal differencing.

The $\max(p, q + 1)$ is not the only state space version of the ARMA model.
**TODO** other representations.

For examples of models see [Eric Zivot's notes](http://faculty.washington.edu/ezivot/econ584/notes/statespacemodels.pdf)

### AR(2)

The AR(2) model is,
$$
\begin{aligned}[t]
y_t &= \mu + \phi_1 y_{t - 1} + \phi_2 y_{t - 2} + \eta_t & \eta_t \sim N(0, \sigma^2) .
\end{aligned}
$$

One way to represent it is to define the states as 
$$
\vec{\alpha}_t = (y_t, y_{t - 1})',
$$
so that the state space form is,
$$
y_t = 
\begin{bmatrix} 1 & 0 \end{bmatrix} 
\begin{bmatrix} 
y_t \\
y_{t - 1} \\
\end{bmatrix} 
+ \eta_t \\
\begin{bmatrix}
y_t \\
y_{t - 1}
\end{bmatrix}
&= 
\begin{bmatrix}
\mu \\
0
\end{bmatrix}
\begin{bmatrix}
\phi_1 & \phi_2 \\
1 & 0
\end{bmatrix}
\begin{bmatrix}
y_t \\
y_{t - 2}
\end{bmatrix}
+ 
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\eta_t .
$$

An alternate state space representation of AR(2) models is
$$
\begin{aligned}
y_t &= \mu + \gamma_t \\
\gamma_t &= \phi_1 \gamma_{t - 1} + \phi_2 \gamma_{t - 2} + \eta_t
\end{aligned}
$$
The state vector is $\vec{\alpha}_t = (\gamma_t, \gamma_{t- 1})'$, and the observation and state quations are,
$$
\begin{aligned}[t]
y_t &= 
\mu +
\begin{bmatrix}
1 & 0
\end{bmatrix}
\begin{bmatrix}
\gamma_t  \\
\gamma_{t - 1}
\end{bmatrix}
\\
\begin{bmatrix}
\gamma_t  \\
\gamma_{t - 1}
\end{bmatrix}
&= 
\begin{bmatrix}
\phi_1 & \phi_2 \\
1 & 0
\end{bmatrix}
\begin{bmatrix}
\gamma_t  \\
\gamma_{t - 1}
\end{bmatrix}
+
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\eta_t
\end{aligned}
$$

Another representation is,
The state vector is $\vec{\alpha}_t = (y_t, \phi_2 y_{t- 1})'$, and the observation and state quations are,
$$
\begin{aligned}[t]
y_t &= \begin{bmatrix} 1 & 0 \end{bmatrix} \vec{\alpha}_t \\
\vec{\alpha}_t &= 
\begin{bmatrix}
\phi_1 & 1 \\
\phi_2 & 0
\end{bmatrix}
\vec{\alpha}_t
+
\begin{bmatrix}
\mu \\
0
\end{bmatrix}
+
\begin{bmatrix}
1 \\
0 
\end{bmatrix}
\eta_t
\end{aligned}
$$

### AR(p)

Form in [@WestHarrison1997, p. 297]
A SSM form of the AR(p) model,
$$
y_t = \mu + \sum_{j = 1}^p \phi_j (y_{t - j} - \mu) + \varepsilon_t
$$
where
$$
\begin{aligned}[t]
y_t &=
\begin{bmatrix}
1 & 0 & 0 & 0 & \dots & 0 & 0
\end{bmatrix}
\vec{\alpha}_t \\
\vec{\alpha}_{t + 1} &=
\begin{bmatrix}
\phi_1 & \phi_2 & \phi_3 & \cdots & \phi_p \\
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
\vdots & \vdots &  & \ddots & \vdots \\
0 & 0 & \cdots & 1 & 0
\end{bmatrix}
\vec{\alpha}_t
+
\begin{bmatrix}
1  \\
0  \\
0  \\
\vdots  \\
0
\end{bmatrix}
\eta_t &
\eta_t &\sim N(0, Q)
\end{aligned}
$$
Note that $r = 1$.
