## Australian Election Polling

Example from Simon Jackman's textbook (Ex 9.3) and 2005 paper.

The data consist of 239 polls by the Australian pollsters (Newspoll, Nielsen, Morgan, and Galaxy) betwen the October 9, 2004, and November 24, 2007 Australian Federal elections.
```{r}
data("AustralianElectionPolling", package = "pscl")
glimpse(AustralianElectionPolling)
```

We will estimate the the proportion of the population that will vote the Australian Labor Party (ALP) in a House of Representatives election for each day between the elections. 
We model this as 

$$
\begin{aligned}[t]
y_{j,t} &= \delta_{j} + \xi_t + \varepsilon_{j,t} & \varepsilon_{j,t} & \sim N\left(0, \frac{y_{j,t} (1 - y_{j,t})}{r_{j,t}} \right) \\
\xi_t & \xi_{t - 1} + \omega_t & \omega_{t} & \sim N(0, \sigma_{\omega})
\end{aligned}
$$
The observation variances are treated as known, and derived from the sample size and results of the poll.
Jackman 2012 (p. 475) puts a prior on the state variance to ensure that the daily changes in thestate are not too large, with a 95% interval of $\pm 2%$, implying $\sigma_{\omega} = 0.01$.

Polls have between 500 to 2,600 respondents, with a median of 1,156.
While most of the polls use complex survey methods such as post-stratification weights to adjust for non-response, for the purposes of this analysis we will use the stated sample size of the poll as its effective size, and use that to construct the measurement error. There are 1,142 days in the period under consideration.

The unique polling firms and number of polls are,
```{r}
AustralianElectionPolling %>% group_by(org) %>% tally()
```
The face-to-face and phone polls by Morgan are treated separately.
Each polling firm will be given it's own "house effect" term to allow them to 
be systematically biased.
However, we will require that the average of the house effects is zero; 
meaning that while each polling firm may be biased, on average they are not.
$$
\delta_j \sim N(0, d)
$$
Jackman uses a fixed value of $d$ that gives a 95% interval spanning from -0.15 to .15. This corresponds to $d = 0.075$.

In the 2004 election the Australian Labor Party (ALP) won 37.6% percent of
first preferences, and in 2007 they won 43.4%.
These will be treated as coming from a source with no house effect and an infinitely large sample size.

```{rAustralianElectionPolling-data}
library("dplyr")
data("AustralianElectionPolling", package = "pscl")
glimpse(AustralianElectionPolling)
```

Unique polling organizations (Morgan face-to-face and phone polls treated separately):
```{r AustralianElectionPolling-orgs}
AustralianElectionPolling %>% group_by(org) %>% tally()
```

Date of the poll is the median day (rounded down) for when they are in the field.

```{r aus_elections}
aus_elections <-
  bind_rows(
    data_frame(date = as.Date("2004-10-09"), ALP = 37.6, sd = .00025),
    data_frame(date = as.Date("2007-11-24"), ALP = 43.4, sd = .00025)
  )

aus_polling <-
  AustralianElectionPolling %>%
  group_by(org, startDate, endDate) %>%
  # There are two Nielson polls on 2007-11-19 to 21.
  summarize(ALP = weighted.mean(ALP, sampleSize),
            sampleSize = sum(sampleSize)) %>%
  ungroup() %>%
  mutate(date = floor_date(as.Date(startDate) + difftime(endDate, startDate, unit = "days"), unit = "day"),
         y = ALP / 100,
         sd = sqrt(y * (1 - y) / sampleSize),
         org = as.character(org)) %>%
  select(date, org, y, sd) %>%
  bind_rows(select(mutate(aus_elections, y = ALP / 100, org = "Election"), -ALP)) %>%
  mutate(time = as.integer(difftime(date, as.Date("2004-10-09"), unit = "days")) + 1)

datelist <-
  data_frame(date = seq(min(aus_polling[["date"]]), max(aus_polling[["date"]]), by = "days"),
             time = min(aus_polling[["time"]]):max(aus_polling[["time"]]))

polling_values <-
  aus_polling %>%
  select(date, time, org, y) %>%
  spread(org, y) %>%
  full_join(select(datelist, date), by = "date") %>%
  arrange(date) %>%
  select(-time)

polling_sd <-
  aus_polling %>%
  select(date, time, org, sd) %>%
  spread(org, sd) %>%
  full_join(select(datelist, date), by = c("date")) %>%
  arrange(date) %>%  
  select(-time)


aus_elec_data <-
  within(list(), {
    y <- as.matrix(select(polling_values, -date))
    # missing <- ssm_process_na(y)
    # p_t <- missing$n
    # y_idx <- missing$idx
    miss <- matrix(as.integer(is.na(y)), nrow = nrow(y), ncol = ncol(y))
    #rm(missing)
    y[is.na(y)] <- 0
    n <- nrow(y)
    p <- ncol(y)
    sigma_eps <- as.matrix(select(polling_sd, -date)) %>%
      apply(2, function(.) if_else(is.na(.), median(., na.rm = TRUE), .))
    sigma_delta <- .0075 # prior on house effects. p. 479. Jackman text.
    zeta <- 0.1
    a1 <- array(0.5)
    P1 <- matrix(0.25, 1, 1)
  })

```

```{r}
polling_mod <- ssm_stan_model("polling.stan")
polling_samples <-
  sampling(polling_mod, data = aus_elec_data, iter = 2000, chains = 1,
           init = list(list(delta = rep(0, aus_elec_data[["p"]] - 1),
                            sigma_eta = 0.005,
                            labmda = rep(1 / aus_elec_data[["n"]], aus_elec_data[["n"]]))))
polling_summary <- tidy_stan_summary(summary(polling_samples))
```

```{r}
ggplot(aus_polling, aes(x = date, y = y,
                        ymin = y - 2 * sd,
                        ymax = y + 2 * sd,
                        colour = org)) +
  geom_pointrange() +
  theme_minimal()
```

```{r}
polling_samples <- polling_summary[["all"]] %>%
  left_join(datelist, by = c("dim_1" = "time"))

states <- filter(polling_samples, parameter == "filtered", dim_2 == 16)

ggplot() +
  geom_ribbon(data = states,
              aes(x = date, ymin = mean - 2 * sd, ymax = mean + 2 * sd), alpha = 0.3) +
  geom_line(data = states,
            aes(x = date, y = mean)) +
  #geom_point(data = aus_polling, aes(x = date, y = y, colour = org)) +
  theme_minimal()
```

```{r}
filter(polling_summary[["all"]], parameter == "delta") %>%
  select(parname, mean, se_mean, p2.5, p97.5, n_eff, Rhat)
```

